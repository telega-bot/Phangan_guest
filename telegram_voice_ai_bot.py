
import os
import openai
import tempfile
import speech_recognition as sr
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, ContextTypes, CommandHandler,
    MessageHandler, filters
)
from pydub import AudioSegment

# === –ó–ê–ú–ï–ù–ò –Ω–∞ —Å–≤–æ–∏ –∫–ª—é—á–∏ ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
openai.api_key = os.getenv("OPENAI_API_KEY")

# –ü–∞–º—è—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
user_contexts = {}

# –ö–Ω–æ–ø–∫–∏
keyboard = ReplyKeyboardMarkup(
    [["rent", "places", "trips", "support"]],
    resize_keyboard=True
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    if user_id not in user_contexts:
        user_contexts[user_id] = []
    user_contexts[user_id].append({"role": "user", "content": text})

    # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 100 —Å–æ–æ–±—â–µ–Ω–∏–π)
    user_contexts[user_id] = user_contexts[user_id][-10:]

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=user_contexts[user_id]
    )

    reply = response["choices"][0]["message"]["content"]
    user_contexts[user_id].append({"role": "assistant", "content": reply})
    await update.message.reply_text(reply, reply_markup=keyboard)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    voice = await update.message.voice.get_file()
    with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as f_ogg:
        await voice.download_to_drive(custom_path=f_ogg.name)
        ogg_path = f_ogg.name

    wav_path = ogg_path.replace(".ogg", ".wav")
    AudioSegment.from_ogg(ogg_path).export(wav_path, format="wav")

    recognizer = sr.Recognizer()
    with sr.AudioFile(wav_path) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data)
            update.message.text = text  # –ø–æ–¥—Å—Ç–∞–≤–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
            await handle_text(update, context)
        except sr.UnknownValueError:
            await update.message.reply_text("Couldn't recognize the voice üòî")

    os.remove(ogg_path)
    os.remove(wav_path)

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Hi! I'm a voice AI bot with buttons. Ask a question or send a voice message üé§", reply_markup=keyboard)

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(MessageHandler(filters.VOICE, handle_voice))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

# –ó–∞–ø—É—Å–∫
app.run_polling()
